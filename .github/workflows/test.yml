name: Test Setup KubeSolo Action

on:
  push:
    branches:
      - main
      - javascript-action-with-cleanup
  pull_request:
  workflow_dispatch:

# Cancel in-progress runs for the same workflow on the same branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Job 1: Basic functionality test - setup, use KubeSolo, cleanup runs automatically
  test-kubesolo-functionality:
    runs-on: ubuntu-24.04
    name: Test KubeSolo Functionality
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Check initial state
        run: |
          echo "=== Checking Initial System State ==="
          systemctl is-active docker && echo "✓ Docker is active" || echo "✗ Docker is not active"
          systemctl is-active containerd && echo "✓ containerd is active" || echo "✗ containerd is not active"
          which docker && echo "✓ Docker binary: $(which docker)" || echo "✗ Docker not found"
          
      - name: Setup KubeSolo
        id: kubesolo
        uses: ./
        with:
          version: 'latest'
          wait-for-ready: 'true'
          timeout: '120'
      
      - name: Verify KubeSolo is installed and running
        run: |
          echo "=== Verifying KubeSolo Installation ==="
          which kubesolo && echo "✓ KubeSolo binary found" || (echo "✗ KubeSolo binary not found" && exit 1)
          systemctl is-active kubesolo && echo "✓ KubeSolo service is active" || (echo "✗ KubeSolo service not active" && exit 1)
          
      - name: Verify Docker/containerd are disabled
        run: |
          echo "=== Verifying Container Runtimes Are Disabled ==="
          
          # Docker should be stopped and backed up
          if systemctl is-active docker >/dev/null 2>&1; then
            echo "✗ Docker should be stopped but is still active"
            exit 1
          fi
          echo "✓ Docker is stopped"
          
          [ -f /usr/bin/docker.bak ] && echo "✓ Docker binary backup exists" || (echo "✗ Docker backup not found" && exit 1)
          
          # containerd should be stopped and backed up
          if systemctl is-active containerd >/dev/null 2>&1; then
            echo "✗ containerd should be stopped but is still active"
            exit 1
          fi
          echo "✓ containerd is stopped"
          
          [ -f /usr/bin/containerd.bak ] && echo "✓ containerd binary backup exists" || (echo "✗ containerd backup not found" && exit 1)
      
      - name: Test kubectl access
        run: |
          echo "=== Testing Kubernetes Functionality ==="
          export KUBECONFIG=${{ steps.kubesolo.outputs.kubeconfig }}
          kubectl version --client
          kubectl cluster-info
          kubectl get nodes
          kubectl get pods -A
          
      - name: Deploy test workload
        run: |
          echo "=== Deploying Test Workload ==="
          export KUBECONFIG=${{ steps.kubesolo.outputs.kubeconfig }}
          
          kubectl create deployment nginx --image=nginx:alpine
          kubectl expose deployment nginx --port=80 --type=ClusterIP
          kubectl wait --for=condition=available --timeout=60s deployment/nginx
          
          # Test connectivity
          POD_NAME=$(kubectl get pod -l app=nginx -o jsonpath='{.items[0].metadata.name}')
          kubectl exec $POD_NAME -- wget -O- http://localhost:80 | grep -q "Welcome to nginx"
          echo "✓ Workload is functioning correctly"
          
      # NOTE: Cleanup runs automatically via post: hook after this job completes
      
  # Job 2: CRITICAL TEST - Verify cleanup worked by running the action again
  # This simulates a realistic scenario: a subsequent workflow that also needs KubeSolo
  # If cleanup didn't work, this job would fail because Docker/containerd would still be masked
  test-cleanup-restoration:
    runs-on: ubuntu-24.04
    name: Verify Cleanup Restores System State
    needs: test-kubesolo-functionality
    if: always()
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        
      - name: Verify Docker is functional BEFORE running KubeSolo
        run: |
          echo "=== CRITICAL TEST: Verifying Docker Works Before KubeSolo ==="
          echo "This proves cleanup from the previous job restored the system properly"
          echo ""
          
          # If cleanup didn't work, Docker would still be masked and this would fail
          if ! systemctl is-active docker >/dev/null 2>&1; then
            echo "✗ CRITICAL FAILURE: Docker is not active"
            echo "This means the previous job's cleanup did NOT restore Docker!"
            systemctl status docker || true
            exit 1
          fi
          echo "✓ Docker service is active"
          
          # Verify Docker actually works
          if ! docker ps >/dev/null 2>&1; then
            echo "✗ CRITICAL FAILURE: 'docker ps' does not work"
            echo "This means the previous job's cleanup did NOT properly restore Docker!"
            docker ps || true
            exit 1
          fi
          echo "✓ 'docker ps' works"
          
          # Try running a container
          if ! docker run --rm hello-world 2>&1 | grep -q "Hello from Docker"; then
            echo "✗ CRITICAL FAILURE: Cannot run Docker containers"
            echo "This means the previous job's cleanup did NOT properly restore Docker!"
            exit 1
          fi
          echo "✓ Docker can run containers"
          
          echo ""
          echo "=========================================="
          echo "✓✓✓ SUCCESS: CLEANUP RESTORED DOCKER ✓✓✓"
          echo "=========================================="
          
      - name: Verify containerd is functional BEFORE running KubeSolo
        run: |
          echo "=== Verifying containerd Was Restored ==="
          
          if ! systemctl is-active containerd >/dev/null 2>&1; then
            echo "✗ CRITICAL FAILURE: containerd is not active"
            echo "This means the previous job's cleanup did NOT restore containerd!"
            systemctl status containerd || true
            exit 1
          fi
          echo "✓ containerd service is active"
          
          which containerd >/dev/null && echo "✓ containerd binary exists" || (echo "✗ containerd binary missing" && exit 1)
          
      - name: Verify no KubeSolo remnants from previous job
        run: |
          echo "=== Verifying Previous Cleanup Was Complete ==="
          
          [ ! -f /usr/local/bin/kubesolo ] && echo "✓ KubeSolo binary removed" || (echo "✗ KubeSolo binary still exists" && exit 1)
          [ ! -d /var/lib/kubesolo ] && echo "✓ KubeSolo data dir removed" || (echo "✗ KubeSolo data dir still exists" && exit 1)
          [ ! -f /etc/systemd/system/kubesolo.service ] && echo "✓ KubeSolo service removed" || (echo "✗ KubeSolo service file still exists" && exit 1)
          
          # No backup files should remain
          if ls /usr/bin/*.bak >/dev/null 2>&1; then
            echo "✗ Backup files still exist:"
            ls -la /usr/bin/*.bak
            exit 1
          fi
          echo "✓ No backup files remaining"
          
      - name: Run KubeSolo again to prove it works after cleanup
        id: kubesolo
        uses: ./
        with:
          version: 'latest'
          timeout: '120'
        
      - name: Verify second KubeSolo instance works
        run: |
          echo "=== Verifying Second KubeSolo Installation Works ==="
          export KUBECONFIG=${{ steps.kubesolo.outputs.kubeconfig }}
          kubectl get nodes
          kubectl get pods -A
          kubectl create deployment nginx --image=nginx:alpine
          kubectl wait --for=condition=available --timeout=60s deployment/nginx
          echo "✓ Second KubeSolo instance is fully functional"
          
      # Cleanup will run automatically again for this job
      
  # Job 3: FINAL TEST - Run a pure Docker workflow after everything
  # This proves the action can be used multiple times without breaking the system
  test-docker-after-multiple-runs:
    runs-on: ubuntu-24.04
    name: Verify Docker Works After Multiple KubeSolo Runs
    needs: test-cleanup-restoration
    if: always()
    steps:
      - name: FINAL TEST - Verify Docker is fully functional
        run: |
          echo "=== FINAL TEST: Docker After Multiple KubeSolo Runs ==="
          echo "This simulates a workflow that needs Docker after KubeSolo has been used"
          echo ""
          
          # Check Docker service
          if ! systemctl is-active docker >/dev/null 2>&1; then
            echo "✗ FAIL: Docker service not active"
            systemctl status docker || true
            exit 1
          fi
          echo "✓ Docker service is active"
          
          # Pull and run a container
          echo "Pulling nginx:alpine..."
          docker pull nginx:alpine
          
          echo "Running container..."
          CONTAINER_ID=$(docker run -d -p 8080:80 nginx:alpine)
          echo "Started container: $CONTAINER_ID"
          
          # Wait and test
          sleep 3
          curl -f http://localhost:8080 >/dev/null 2>&1 || (echo "✗ Container not responding" && exit 1)
          echo "✓ Container is responding"
          
          # Cleanup
          docker stop $CONTAINER_ID >/dev/null
          docker rm $CONTAINER_ID >/dev/null
          
          echo ""
          echo "=========================================="
          echo "✓✓✓ COMPLETE SUCCESS ✓✓✓"
          echo "=========================================="
          echo ""
          echo "The setup-kubesolo action:"
          echo "  ✓ Installs and runs KubeSolo successfully"
          echo "  ✓ Properly disables Docker/containerd during use"
          echo "  ✓ Completely restores system state after cleanup"
          echo "  ✓ Can be run multiple times without issues"
          echo "  ✓ Allows subsequent workflows to use Docker normally"
          echo ""
          echo "System state restoration is PERFECT!"